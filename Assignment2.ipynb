{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushbaghel01/InvestX_asgnmnt/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 559,
      "metadata": {
        "id": "F3NmyDkdaw3f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "#from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE : All the code is same as that is provided in the google meet, The code for finding efficiency of the below model is included in the last code blocks.**"
      ],
      "metadata": {
        "id": "LLKVZ8YjNvWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Train.csv')\n",
        "print(df.head())\n",
        "df=df.head(150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aH7bA5fdNV8",
        "outputId": "5af23be5-229a-4db5-ec9e-3ab9b34b2ff9"
      },
      "execution_count": 560,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date    Stock  liabilities      equity  total_assets  current_assets  \\\n",
            "0  2006-07-31  Stock 1   625.898686  925.086518   1550.985204      675.789905   \n",
            "1  2006-08-31  Stock 1   407.387467  903.249093   1310.636561     1023.110983   \n",
            "2  2006-09-29  Stock 1   464.069891  602.668832   1066.738722      709.711673   \n",
            "3  2006-10-31  Stock 1   855.854937  391.375369   1247.230306      649.979564   \n",
            "4  2006-11-30  Stock 1   453.954969  956.490566   1410.445534     1115.594551   \n",
            "\n",
            "   current_liabilities  total_revenue  net_income   dividend  \\\n",
            "0           555.931329     548.488451  251.282553  68.184030   \n",
            "1          1295.186240     513.446432  207.576940  42.232672   \n",
            "2           598.719338     503.519871  133.719700  28.835722   \n",
            "3           733.594339     596.006397  -76.881818   0.000000   \n",
            "4          1152.274711     965.939247 -309.204301   0.000000   \n",
            "\n",
            "   shares_outstanding       price  \n",
            "0             1040831  100.000000  \n",
            "1             1046649  101.924169  \n",
            "2             1094158  103.166191  \n",
            "3             1018574  104.478956  \n",
            "4             1036293  104.160907  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(df)[2:12]\n",
        "print(cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLtCdVuQdaqD",
        "outputId": "f0a7c8c9-82bf-4dc2-f8e0-9b3f7a740167"
      },
      "execution_count": 561,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['liabilities', 'equity', 'total_assets', 'current_assets', 'current_liabilities', 'total_revenue', 'net_income', 'dividend', 'shares_outstanding', 'price']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training = df[cols].astype(float)"
      ],
      "metadata": {
        "id": "kW6fJrsveCsy"
      },
      "execution_count": 562,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(df_for_training)\n",
        "df_for_training_scaled = scaler.transform(df_for_training)"
      ],
      "metadata": {
        "id": "sMJHDh0Eea0u"
      },
      "execution_count": 563,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = []\n",
        "trainY = []"
      ],
      "metadata": {
        "id": "UXLCuxpYefYU"
      },
      "execution_count": 564,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_future = 1  # Number of days we want to look into the future based on the past days.\n",
        "n_past = 14 # Number of past days we want to use to predict the future."
      ],
      "metadata": {
        "id": "SlZmQQHaepNo"
      },
      "execution_count": 565,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
        "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
        "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 9])\n",
        "\n",
        "trainX, trainY = np.array(trainX), np.array(trainY)\n",
        "\n",
        "print('trainX shape == {}.'.format(trainX.shape))\n",
        "print('trainY shape == {}.'.format(trainY.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UGlhknUfFXB",
        "outputId": "dc80d07d-c965-4d5d-dd9e-948c3ae38850"
      },
      "execution_count": 566,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainX shape == (136, 14, 10).\n",
            "trainY shape == (136, 1).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training_scaled;"
      ],
      "metadata": {
        "id": "Mf2hun7pvqvf"
      },
      "execution_count": 567,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainY;"
      ],
      "metadata": {
        "id": "A4HvqbAkv1ZW"
      },
      "execution_count": 568,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True)) \n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(trainY.shape[1]))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLJ_fEZ8foI3",
        "outputId": "cafbce56-0e3d-44de-d204-dea6686b063f"
      },
      "execution_count": 569,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_48 (LSTM)              (None, 14, 64)            19200     \n",
            "                                                                 \n",
            " lstm_49 (LSTM)              (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,649\n",
            "Trainable params: 31,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(trainX, trainY, epochs=5, batch_size=3, validation_split=0.1, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR-gELFqhCt3",
        "outputId": "44ba76a4-b233-422f-b0d6-0d9271819a3e"
      },
      "execution_count": 570,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "41/41 [==============================] - 4s 24ms/step - loss: 0.5836 - val_loss: 0.0522\n",
            "Epoch 2/5\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 0.1476 - val_loss: 0.0407\n",
            "Epoch 3/5\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.0672 - val_loss: 0.0371\n",
            "Epoch 4/5\n",
            "41/41 [==============================] - 1s 17ms/step - loss: 0.0578 - val_loss: 0.0348\n",
            "Epoch 5/5\n",
            "41/41 [==============================] - 1s 16ms/step - loss: 0.0416 - val_loss: 0.0522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "from pandas.tseries.offsets import CustomBusinessDay\n",
        "us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())"
      ],
      "metadata": {
        "id": "ncph6lCWjfQ_"
      },
      "execution_count": 571,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df2= df.head(150)\n",
        "train_dates = pd.to_datetime(df2['Date'])"
      ],
      "metadata": {
        "id": "DSZrHFBYj7iK"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_past = 1\n",
        "n_days_for_prediction=50  #let us predict past 15 days\n",
        "\n",
        "predict_period_dates = pd.date_range(list(train_dates)[-n_past], periods=n_days_for_prediction, freq='M').tolist()\n",
        "print(predict_period_dates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAZn0dxejZ-b",
        "outputId": "d913d346-3876-4d32-999d-a338ed25d5df"
      },
      "execution_count": 573,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Timestamp('2018-12-31 00:00:00', freq='M'), Timestamp('2019-01-31 00:00:00', freq='M'), Timestamp('2019-02-28 00:00:00', freq='M'), Timestamp('2019-03-31 00:00:00', freq='M'), Timestamp('2019-04-30 00:00:00', freq='M'), Timestamp('2019-05-31 00:00:00', freq='M'), Timestamp('2019-06-30 00:00:00', freq='M'), Timestamp('2019-07-31 00:00:00', freq='M'), Timestamp('2019-08-31 00:00:00', freq='M'), Timestamp('2019-09-30 00:00:00', freq='M'), Timestamp('2019-10-31 00:00:00', freq='M'), Timestamp('2019-11-30 00:00:00', freq='M'), Timestamp('2019-12-31 00:00:00', freq='M'), Timestamp('2020-01-31 00:00:00', freq='M'), Timestamp('2020-02-29 00:00:00', freq='M'), Timestamp('2020-03-31 00:00:00', freq='M'), Timestamp('2020-04-30 00:00:00', freq='M'), Timestamp('2020-05-31 00:00:00', freq='M'), Timestamp('2020-06-30 00:00:00', freq='M'), Timestamp('2020-07-31 00:00:00', freq='M'), Timestamp('2020-08-31 00:00:00', freq='M'), Timestamp('2020-09-30 00:00:00', freq='M'), Timestamp('2020-10-31 00:00:00', freq='M'), Timestamp('2020-11-30 00:00:00', freq='M'), Timestamp('2020-12-31 00:00:00', freq='M'), Timestamp('2021-01-31 00:00:00', freq='M'), Timestamp('2021-02-28 00:00:00', freq='M'), Timestamp('2021-03-31 00:00:00', freq='M'), Timestamp('2021-04-30 00:00:00', freq='M'), Timestamp('2021-05-31 00:00:00', freq='M'), Timestamp('2021-06-30 00:00:00', freq='M'), Timestamp('2021-07-31 00:00:00', freq='M'), Timestamp('2021-08-31 00:00:00', freq='M'), Timestamp('2021-09-30 00:00:00', freq='M'), Timestamp('2021-10-31 00:00:00', freq='M'), Timestamp('2021-11-30 00:00:00', freq='M'), Timestamp('2021-12-31 00:00:00', freq='M'), Timestamp('2022-01-31 00:00:00', freq='M'), Timestamp('2022-02-28 00:00:00', freq='M'), Timestamp('2022-03-31 00:00:00', freq='M'), Timestamp('2022-04-30 00:00:00', freq='M'), Timestamp('2022-05-31 00:00:00', freq='M'), Timestamp('2022-06-30 00:00:00', freq='M'), Timestamp('2022-07-31 00:00:00', freq='M'), Timestamp('2022-08-31 00:00:00', freq='M'), Timestamp('2022-09-30 00:00:00', freq='M'), Timestamp('2022-10-31 00:00:00', freq='M'), Timestamp('2022-11-30 00:00:00', freq='M'), Timestamp('2022-12-31 00:00:00', freq='M'), Timestamp('2023-01-31 00:00:00', freq='M')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(trainX[-n_days_for_prediction:]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omuhi-fFjuzK",
        "outputId": "54afc443-281e-4fca-83aa-77e5e415e785"
      },
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_copies = np.repeat(prediction, df_for_training.shape[1], axis=-1)\n",
        "y_pred_future = scaler.inverse_transform(prediction_copies)[:,9]"
      ],
      "metadata": {
        "id": "A68cGGUlkLp7"
      },
      "execution_count": 575,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_dates = []\n",
        "for time_i in predict_period_dates:\n",
        "    forecast_dates.append(time_i.date())\n",
        "    \n",
        "df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'price':y_pred_future})\n",
        "df_forecast['Date']=pd.to_datetime(df_forecast['Date'])"
      ],
      "metadata": {
        "id": "RRg0e30rkPIK"
      },
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original = df[['Date', 'price']]\n",
        "original['Date']=pd.to_datetime(original['Date'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PbdmSaPkUK7",
        "outputId": "114bd9a5-6c7e-427c-b57a-cbded7641ec3"
      },
      "execution_count": 577,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-577-d6bbd2f4d398>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  original['Date']=pd.to_datetime(original['Date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forecast\n",
        "df_ = pd.read_csv('Train.csv')\n",
        "df_=df_.head(200)\n",
        "predicted_price = df_forecast.price"
      ],
      "metadata": {
        "id": "uQKHlrzh2Jl6"
      },
      "execution_count": 578,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_price = df_.price[150:200]"
      ],
      "metadata": {
        "id": "bEiRXG9hJxpj"
      },
      "execution_count": 579,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in range(50):\n",
        "  l.append(abs(predicted_price[i]-actual_price[150+i])/actual_price[150+i])\n",
        "deviation_rd=np.array(l)\n",
        "rms = np.sqrt(np.mean(np.square(deviation_rd)))\n",
        "efficiency = (1-rms)*100\n",
        "print(efficiency)\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBAVU3ixJwYI",
        "outputId": "bc856e77-1d55-4b2c-f1b8-6d29d6b75404"
      },
      "execution_count": 580,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82.41016582009371\n",
            "[0.2697969055175781, 0.23696153643433326, 0.21774041263788324, 0.22783177117135925, 0.23040454588288264, 0.24196399698436852, 0.23774697376683604, 0.24390436477504884, 0.23227216295904873, 0.2194925405761306, 0.20417815995836153, 0.1874537456011981, 0.1718583974186806, 0.16209021370908766, 0.16127457732410033, 0.16081083559854484, 0.15762509645132045, 0.14685516230099196, 0.15013939671252477, 0.1588597511183781, 0.15452705106148826, 0.1563584366293323, 0.1693996638110431, 0.16979362126554734, 0.154296319820768, 0.13305862621074177, 0.1325433232499023, 0.14907979403165583, 0.13938971065417993, 0.12367246944771128, 0.12590995426946477, 0.11952636806328928, 0.12875355095091068, 0.12349127699501895, 0.1305486591507583, 0.1281460434866936, 0.12504705320711995, 0.11392030090672743, 0.12275231627326053, 0.14410578918084158, 0.16274325991465521, 0.15896293063299852, 0.15420140768548876, 0.16209405824316914, 0.16941515583326378, 0.1744516722896381, 0.19147433810631537, 0.2056419090801776, 0.2189497396515676, 0.20171300443927007]\n"
          ]
        }
      ]
    }
  ]
}